
## 1. Описание Проекта

**SimpleWAF** — это высокопроизводительный программный комплекс, предназначенный для фильтрации, перехвата и глубокого анализа сетевого трафика (DPI) в условиях соревнований по информационной безопасности (Attack-Defence CTF).

Проект решает задачу защиты уязвимых сервисов без модификации их исходного кода. Он выступает в роли прозрачного прокси-сервера (Man-in-the-Middle), который перехватывает TCP-соединения, анализирует их содержимое на уровне протокола приложений (L7 HTTP) и принимает решения о блокировке или маркировке запросов на основе динамически загружаемых правил.

Главная особенность системы — гибкость. В отличие от классических WAF (Web Application Firewall), где правила ограничены жестким синтаксисом, этот проект позволяет описывать логику фильтрации на языке Python. Это дает возможность реализовывать проверки любой сложности, включая сложные регулярные выражения, логические условия и анализ тела запроса, что критически важно для отражения 0-day эксплойтов в реальном времени.

---

## 2. Архитектура Системы

Архитектура проекта разделена на два ключевых слоя, что обеспечивает высокую производительность и удобство управления.

### Слой Ядра (Core Layer)
Это "двигатель" системы, работающий в асинхронном режиме для обеспечения максимальной пропускной способности (>1000 RPS).

1.  **Асинхронный TCP Прокси (`TcpProxy`):**
    *   Реализован на базе библиотеки `asyncio`.
    *   Обеспечивает перехват соединений без блокировки основного потока.
    *   Управляет буферизацией данных (с защитой от переполнения памяти) для корректного анализа DPI.
    *   Реализует отказоустойчивость: если трафик не является HTTP, он прозрачно пропускается (режим Passthrough), чтобы не нарушать работу бинарных сервисов.

2.  **HTTP Парсер (`HttpStreamParser`):**
    *   Использует библиотеку `httptools` (биндинг к высокопроизводительному C-парсеру nodejs/http-parser).
    *   Разбирает поток байт на заголовки, методы, пути и тело запроса.
    *   Позволяет анализировать как входящие запросы (Requests), так и исходящие ответы (Responses).

3.  **Движок Правил (`RuleEngine`):**
    *   Компилирует и исполняет правила, написанные на Python.
    *   **Динамическая загрузка:** Правила применяются "на лету" без перезагрузки сервиса.
    *   **Иерархия приоритетов:**
        *   **Сервисные правила** (привязанные к конкретному порту) имеют приоритет над **Глобальными**.
        *   Действие `ACCEPT` (разрешить) имеет приоритет над `DROP` (запретить), что позволяет создавать гибкие белые списки.
    *   Автоматически маркирует сессии тегами при срабатывании блокировок.

4.  **Менеджер Сессий (`SessionManager`):**
    *   Решает проблему "фрагментированного" анализа.
    *   Агрегирует разрозненные TCP-соединения в единые **Логические Сессии Пользователя** на основе IP-адреса и временного окна.
    *   Позволяет отслеживать хронологию атаки целиком, а не отдельными пакетами.

### Пользовательский Слой (User Layer)
Предоставляет интерфейс для взаимодействия оператора с системой.

1.  **Web API (`FastAPI`):**
    *   RESTful API для управления правилами, получения статистики и данных о сессиях.
    *   Обеспечивает безопасность через HTTP Basic Auth.

2.  **Веб-интерфейс (SPA Dashboard):**
    *   Написан на Vanilla JS (без тяжелых фреймворков) для быстрой загрузки.
    *   **Дашборд:** Таблица сессий в реальном времени с цветовой кодировкой (Красный — атака заблокирована, Желтый — подозрительная активность).
    *   **Редактор Правил:** Полноценная IDE в браузере с деревом файлов, подсветкой синтаксиса и возможностью переименования/удаления файлов.
    *   **Генератор Правил:** Инструмент для создания шаблона правила в один клик на основе перехваченного запроса.

---

## 3. Технологический Стек и Решения

Выбор технологий обусловлен требованиями к производительности и надежности в условиях CTF:

*   **Язык:** Python 3.12+ (современные возможности типизации и асинхронности).
*   **Concurrency:** `asyncio` — позволяет обрабатывать тысячи одновременных соединений в одном потоке, избегая накладных расходов на переключение контекста потоков ОС.
*   **DPI Parser:** `httptools` — обеспечивает парсинг HTTP-протокола со скоростью, близкой к C/C++, минимизируя задержку (latency).
*   **Storage:** `aiosqlite` — асинхронная обертка над SQLite. Выбрана для простоты развертывания (файловая БД) и отсутствия внешних зависимостей (как PostgreSQL), при этом не блокирует Event Loop при записи логов.
*   **Frontend:** Чистый HTML/JS/CSS. Обеспечивает мгновенный отклик интерфейса и простоту модификации во время соревнования.

---

## 4. Функциональные Возможности

### Умная Фильтрация
Система позволяет писать правила вида:
```python
# Если в User-Agent есть 'curl' ИЛИ в теле запроса есть SQL-инъекция
if 'curl' in request.headers.get('User-Agent', '') or 'union select' in request.data.lower():
    action.drop() # Блокировать соединение
```
Это дает полный контроль над трафиком.

### Агрегация и Аналитика
Вместо тысячи разрозненных строк логов, оператор видит **Сессии**. При клике на сессию открывается детальная хронология всех запросов и ответов ("Stream View"), где можно увидеть, какой именно запрос вызвал срабатывание правила.

### Инструменты Продуктивности
*   **Copy as cURL:** Любой перехваченный запрос можно скопировать как готовую команду `curl` для повторного воспроизведения (Replay attack / Debug).
*   **Rule Generator:** Видите атаку? Нажмите "Create Rule", выберите галочками признаки (IP, Путь, User-Agent), и система сама создаст код блокировки.
*   **Wiki:** Встроенная документация на двух языках (RU/EN) с примерами синтаксиса.

---

## 5. Алгоритм Работы

1.  **Start:** Запуск асинхронного сервера (`run.py`), инициализация БД и Движка Правил.
2.  **Connection:** При входящем подключении прокси открывает сокет к целевому сервису (Backend).
3.  **Buffering:** Данные накапливаются в буфере до тех пор, пока парсер не определит конец HTTP-заголовков.
4.  **Inspection (DPI):**
    *   Сформированный объект `HttpRequest` передается в `RuleEngine`.
    *   Проверяются правила сервиса -> затем глобальные правила.
    *   Выносится вердикт: `ACCEPT`, `DROP` или `MARK`.
5.  **Decision:**
    *   Если `DROP`: Соединение с клиентом разрывается, событие логируется с пометкой "Blocked".
    *   Если `ACCEPT/MARK`: Данные передаются на Backend.
6.  **Response:** Ответ от сервера также проходит через прокси (и может быть проанализирован) и возвращается клиенту.
7.  **Logging:** Все метаданные (заголовки, время, вердикт) асинхронно пишутся в `db.sqlite`.

---

## 6. Установка и Запуск

Проект разработан для развертывания в контейнере или на "голом" Linux сервере (Ubuntu/Debian).

1.  **Установка зависимостей:**
    ```bash
    pip install -r requirements.txt
    ```

2.  **Настройка:**
    В файле `config.py` можно задать порты прослушивания, адрес бэкенда и учетные данные администратора.

3.  **Запуск:**
    ```bash
    python run.py
    ```
    *   Веб-интерфейс будет доступен по адресу: `http://<IP>:57230`
    *   Прокси начнет фильтровать трафик на порту `8080` (по умолчанию).

---

## 7. Пример Правил

Правила хранятся в структурированных папках (`rules/global`, `rules/services/<port>`), что позволяет легко управлять защитой разных сервисов.

**Пример защиты от Path Traversal:**
```python
import re
# Блокируем попытки выхода из директории
if re.search(r'\.\./', request.path) or '%2e%2e' in request.path.lower():
    action.drop()
```

**Пример белого списка для локальной сети:**
```python
# Разрешить все запросы с локального интерфейса
if request.client_ip.startswith('192.168.1.'):
    action.accept()
```
